{"title":"Nvidia claims 10x cost savings with open-source inference models","path":"/article/4132357/nvidia-claims-10x-cost-savings-with-open-source-inference-models.html","site":"https://www.networkworld.com","atUri":"at://did:plc:qzjwstutqk2cy7df7jbzd2hx/site.standard.document/3mesj4idpbho2","publishedAt":"2026-02-13T20:39:13Z","tags":"Artificial Intelligence, CPUs and Processors;AI inferencing;cost reductions;Baseten;DeepInfra;Fireworks AI;Together AI;**Related** : [**More Nvidia news and insights**;blog post;Reports of Nvidia/OpenAI deal in jeopardy are overblown, says Nvidia’s CEO;Eying AI factories, Nvidia buys bigger stake in CoreWeave;China clears Nvidia H200 sales to tech giants, reshaping AI data center plans;Nvidia is still working with suppliers on RAM chips for Rubin;RISC-V chip designer SiFive integrates Nvidia NVLink Fusion to power AI data centers;Nvidia H200 chips in China: US says yes, China says no;Lenovo-Nvidia partnership targets faster AI infrastructure rollouts;Top 10 Nvidia stories of 2025 – From the data center to the AI factory;HPE loads up AI networking portfolio, strengthens Nvidia, AMD partnerships;Nvidia’s $2B Synopsys stake tests independence of open AI interconnect standard;Nvidia bets on open infrastructure for the agentic AI era with Nemotron 3;Nvidia moves deeper into AI infrastructure with SchedMD acquisition;Nvidia chips sold out? Cut back on AI plans, or look elsewhere"}